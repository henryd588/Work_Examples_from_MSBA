{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIdqRlwn363A"
      },
      "source": [
        "Load PySpark, Libraries, and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD88Rz1fROGI",
        "outputId": "2931503d-f24f-4c12-9fda-60ad207e30be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.3/spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYIFT_gDRPar"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import *\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import UnivariateFeatureSelector\n",
        "import pyspark.ml.tuning as tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj0EhPeCPQ3e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# read in the headers\n",
        "spambase_headers = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names',\n",
        "                               skiprows=32,\n",
        "                               sep=':',\n",
        "                               names=['header_name', 'description']\n",
        "                               )['header_name'].tolist()\n",
        "\n",
        "# header file does not include label for target column\n",
        "spambase_headers.append('spam')\n",
        "\n",
        "# load the data using the\n",
        "spambase_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data',\n",
        "                          header=None,\n",
        "                          names=spambase_headers\n",
        "                          )\n",
        "spambase_df = spark.createDataFrame(spambase_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEq9vX8j8f5v"
      },
      "outputs": [],
      "source": [
        "#Select all columns except target variable\n",
        "input_cols = spambase_df.columns\n",
        "input_cols.remove('spam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvb9zb0kZTgY"
      },
      "outputs": [],
      "source": [
        "#Test/Train Split\n",
        "(trainData, testData) = spambase_df.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh5wtpCOd3QO"
      },
      "outputs": [],
      "source": [
        "#Stats for evaluating the performance of models\n",
        "def run_models_get_results(pipelines, pipeline_name, train=trainData, test=testData):\n",
        "  results = []\n",
        "  for p, name in zip(pipelines, pipeline_name):\n",
        "    print(f'Processing {name}')\n",
        "    p_fit = p.fit(trainData)\n",
        "    p_prediction = p_fit.transform(testData)\n",
        "\n",
        "    accuracy_BCE = MulticlassClassificationEvaluator(labelCol='spam', predictionCol='prediction', metricName=\"accuracy\")\n",
        "    precision_BCE = MulticlassClassificationEvaluator(labelCol='spam', predictionCol='prediction', metricName=\"precisionByLabel\")\n",
        "    recall_BCE = MulticlassClassificationEvaluator(labelCol='spam', predictionCol='prediction', metricName=\"recallByLabel\")\n",
        "    f1Measure_BCE = MulticlassClassificationEvaluator(labelCol='spam', predictionCol='prediction', metricName=\"f1\")\n",
        "\n",
        "    accuracy = accuracy_BCE.evaluate(p_prediction)\n",
        "    precision = precision_BCE.evaluate(p_prediction)\n",
        "    recall = recall_BCE.evaluate(p_prediction)\n",
        "    f1Measure = f1Measure_BCE.evaluate(p_prediction)\n",
        "\n",
        "    print('Confusion Matrix')\n",
        "    p_prediction.select(\"spam\", \"prediction\").groupBy(\"spam\", \"prediction\").count().show()\n",
        "\n",
        "    print(f'{name}')\n",
        "    print(f'accurary: {accuracy}')\n",
        "    print(f'precision: {precision}')\n",
        "    print(f'recall: {recall}')\n",
        "    print(f'f1 Measure: {f1Measure}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2dwAqF3-SgY"
      },
      "outputs": [],
      "source": [
        "#\"Confusion matrix\" for each model to see how models perfrom on data, seperate from other statistic block depending on need for results in each form\n",
        "def run_models_get_results_get_cost(pipelines, pipeline_name, train=trainData, test=testData):\n",
        "  results = []\n",
        "  for p, name in zip(pipelines, pipeline_name):\n",
        "    print(f'Processing {name}')\n",
        "    p_fit = p.fit(trainData)\n",
        "    p_prediction = p_fit.transform(testData)\n",
        "\n",
        "    True_Positive = p_prediction.where((p_prediction.spam == '1')&(p_prediction.prediction == '1')).count()\n",
        "    True_Negative = p_prediction.where((p_prediction.spam == '0')&(p_prediction.prediction == '0')).count()\n",
        "    False_Positive = p_prediction.where((p_prediction.spam == '0')&(p_prediction.prediction == '1')).count()\n",
        "    False_Negative = p_prediction.where((p_prediction.spam == '1')&(p_prediction.prediction == '0')).count()\n",
        "    Total = p_prediction.count()\n",
        "    Total_Avg_Cost = (False_Positive*10+False_Negative)/Total\n",
        "\n",
        "    print('Confusion Matrix')\n",
        "    p_prediction.select(\"spam\", \"prediction\").groupBy(\"spam\", \"prediction\").count().show()\n",
        "\n",
        "    print(f'{name}')\n",
        "    print(f'True Positive Cost: {True_Positive*0}')\n",
        "    print(f'True Negative Cost: {True_Negative*0}')\n",
        "    print(f'False Positive Cost: {False_Positive*10}')\n",
        "    print(f'False Negative Cost: {False_Negative*1}')\n",
        "    print(f'Total Avg Cost: {Total_Avg_Cost}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czcnPDcC7wbz"
      },
      "source": [
        "Base Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcZus0ujcXHF",
        "outputId": "fe0a05cb-6cb8-463a-a2f5-c449868d3154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Decision_Tree\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   90|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  425|\n",
            "+----+----------+-----+\n",
            "\n",
            "Decision_Tree\n",
            "accurary: 0.9023689877961235\n",
            "precision: 0.9023861171366594\n",
            "recall: 0.9476082004555809\n",
            "f1 Measure: 0.9013838761404175\n",
            "Processing Naive_Bayes\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|  145|\n",
            "|   0|       1.0|  133|\n",
            "|   0|       0.0|  745|\n",
            "|   1|       1.0|  370|\n",
            "+----+----------+-----+\n",
            "\n",
            "Naive_Bayes\n",
            "accurary: 0.8004307250538406\n",
            "precision: 0.8370786516853933\n",
            "recall: 0.8485193621867881\n",
            "f1 Measure: 0.7999317530781043\n",
            "Processing Random_Forest\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   75|\n",
            "|   0|       0.0|  850|\n",
            "|   1|       1.0|  440|\n",
            "|   0|       1.0|   28|\n",
            "+----+----------+-----+\n",
            "\n",
            "Random_Forest\n",
            "accurary: 0.9260588657573582\n",
            "precision: 0.918918918918919\n",
            "recall: 0.9681093394077449\n",
            "f1 Measure: 0.9252549351224462\n",
            "Processing GBT_Classieifer\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   63|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  452|\n",
            "+----+----------+-----+\n",
            "\n",
            "GBT_Classieifer\n",
            "accurary: 0.9217516152189519\n",
            "precision: 0.929608938547486\n",
            "recall: 0.9476082004555809\n",
            "f1 Measure: 0.9214701726938952\n"
          ]
        }
      ],
      "source": [
        "#Pipelines for each simple model without adjustments\n",
        "va = VectorAssembler(inputCols = input_cols, outputCol = 'features')\n",
        "\n",
        "clf = DecisionTreeClassifier(labelCol=\"spam\")\n",
        "clf_pipe = Pipeline(stages=[va, clf])\n",
        "\n",
        "nb = NaiveBayes(labelCol=\"spam\")\n",
        "nb_pipe = Pipeline(stages=[va, nb])\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"spam\")\n",
        "rf_pipe = Pipeline(stages=[va, rf])\n",
        "\n",
        "gbt = GBTClassifier(labelCol = 'spam')\n",
        "gbt_pipe = Pipeline(stages=[va, gbt])\n",
        "\n",
        "pipelines = [clf_pipe, nb_pipe, rf_pipe, gbt_pipe]\n",
        "\n",
        "pipeline_name = ['Decision_Tree', 'Naive_Bayes', 'Random_Forest', 'GBT_Classieifer']\n",
        "\n",
        "results = run_models_get_results(pipelines, pipeline_name, trainData, testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU9EGe0V9yWF",
        "outputId": "a4ecb913-508c-4ee2-898c-f5d3bf6be22f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Decision_Tree\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   90|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  425|\n",
            "+----+----------+-----+\n",
            "\n",
            "Decision_Tree\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 460\n",
            "False Negative Cost: 90\n",
            "Total Avg Cost: 0.3948312993539124\n",
            "Processing Naive_Bayes\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|  145|\n",
            "|   0|       1.0|  133|\n",
            "|   0|       0.0|  745|\n",
            "|   1|       1.0|  370|\n",
            "+----+----------+-----+\n",
            "\n",
            "Naive_Bayes\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 1330\n",
            "False Negative Cost: 145\n",
            "Total Avg Cost: 1.0588657573582196\n",
            "Processing Random_Forest\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   75|\n",
            "|   0|       0.0|  850|\n",
            "|   1|       1.0|  440|\n",
            "|   0|       1.0|   28|\n",
            "+----+----------+-----+\n",
            "\n",
            "Random_Forest\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 280\n",
            "False Negative Cost: 75\n",
            "Total Avg Cost: 0.2548456568557071\n",
            "Processing GBT_Classieifer\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   63|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  452|\n",
            "+----+----------+-----+\n",
            "\n",
            "GBT_Classieifer\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 460\n",
            "False Negative Cost: 63\n",
            "Total Avg Cost: 0.375448671931084\n"
          ]
        }
      ],
      "source": [
        "results = run_models_get_results_get_cost(pipelines, pipeline_name, trainData, testData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2kvGqYand7o"
      },
      "source": [
        "Naive Bayes had the lowest accuracy score and performed on average much worse than any other model. For the other three models generally decision tree performed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iKz_dao70Z9"
      },
      "source": [
        "Scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72nVp6ej7FsB",
        "outputId": "027b9da3-7eab-45c9-aecf-976e093d97bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Decision_Tree\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   90|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  425|\n",
            "+----+----------+-----+\n",
            "\n",
            "Decision_Tree\n",
            "accurary: 0.9023689877961235\n",
            "precision: 0.9023861171366594\n",
            "recall: 0.9476082004555809\n",
            "f1 Measure: 0.9013838761404175\n",
            "Processing Random_Forest\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   75|\n",
            "|   0|       0.0|  850|\n",
            "|   1|       1.0|  440|\n",
            "|   0|       1.0|   28|\n",
            "+----+----------+-----+\n",
            "\n",
            "Random_Forest\n",
            "accurary: 0.9260588657573582\n",
            "precision: 0.918918918918919\n",
            "recall: 0.9681093394077449\n",
            "f1 Measure: 0.9252549351224462\n",
            "Processing GBT_Classieifer\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   63|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  452|\n",
            "+----+----------+-----+\n",
            "\n",
            "GBT_Classieifer\n",
            "accurary: 0.9217516152189519\n",
            "precision: 0.929608938547486\n",
            "recall: 0.9476082004555809\n",
            "f1 Measure: 0.9214701726938952\n"
          ]
        }
      ],
      "source": [
        "#Models with feature scaling added to pipeline\n",
        "scaledFeatureArr = [(col+'_scaled') for col in input_cols]\n",
        "\n",
        "va = [VectorAssembler(inputCols = [col], outputCol = (col+'_vec')) for col in input_cols]\n",
        "\n",
        "ss = [StandardScaler(withMean = True, withStd = True, inputCol = col+'_vec', outputCol = col+'_scaled') for col in input_cols]\n",
        "\n",
        "va2 = VectorAssembler(inputCols = scaledFeatureArr, outputCol = 'features')\n",
        "\n",
        "clf = DecisionTreeClassifier(labelCol=\"spam\", featuresCol='features')\n",
        "clf_pipe = Pipeline(stages = va + ss + [va2, clf])\n",
        "\n",
        "nb = NaiveBayes(labelCol=\"spam\", featuresCol='features')\n",
        "nb_pipe = Pipeline(stages= va + ss + [va2, nb])\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"spam\", featuresCol='features')\n",
        "rf_pipe = Pipeline(stages= va + ss + [va2, rf])\n",
        "\n",
        "gbt = GBTClassifier(labelCol = 'spam', featuresCol='features')\n",
        "gbt_pipe = Pipeline(stages= va + ss +  [va2, gbt])\n",
        "\n",
        "pipelines = [clf_pipe, rf_pipe, gbt_pipe]\n",
        "\n",
        "pipeline_name = ['Decision_Tree', 'Random_Forest', 'GBT_Classieifer']\n",
        "\n",
        "results = run_models_get_results(pipelines, pipeline_name, trainData, testData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnqVGPgTKbx2"
      },
      "source": [
        "Did not include Naive Bayes as NB does not need to be scaled in the same way as the other models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gDenmLIuSb8"
      },
      "source": [
        "As scaling did not seem to make a significant difference in results it will not be used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py5BMZKCtkUc"
      },
      "source": [
        "Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVDsDABV0g17"
      },
      "outputs": [],
      "source": [
        "#Feature selection added to pipeline, feature scaling not included\n",
        "va = VectorAssembler(inputCols = input_cols, outputCol = 'features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRmD7uqj1ezp",
        "outputId": "9c10e3d6-d126-4621-8758-442fa176cd50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UnivariateFeatureSelector_4a666fe3c299"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "sel = UnivariateFeatureSelector(featuresCol=\"features\", outputCol=\"selectedFeatures\", labelCol=\"spam\", selectionMode=\"fpr\")\n",
        "\n",
        "sel.setFeatureType(\"continuous\").setLabelType(\"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0z2gl410rIk"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier(labelCol=\"spam\", featuresCol='selectedFeatures')\n",
        "clf_pipe = Pipeline(stages=[va, sel, clf])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kOjFaA70tbY"
      },
      "outputs": [],
      "source": [
        "nb = NaiveBayes(labelCol=\"spam\", featuresCol='selectedFeatures')\n",
        "nb_pipe = Pipeline(stages=[va, sel, nb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4jnG0cM0vxD"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(labelCol=\"spam\", featuresCol='selectedFeatures')\n",
        "rf_pipe = Pipeline(stages=[va, sel, rf])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc_ToCKr0zLs"
      },
      "outputs": [],
      "source": [
        "gbt = GBTClassifier(labelCol = 'spam', featuresCol='selectedFeatures')\n",
        "gbt_pipe = Pipeline(stages=[va, sel, gbt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTBLaD0k078I"
      },
      "outputs": [],
      "source": [
        "pipelines = [clf_pipe, nb_pipe, rf_pipe, gbt_pipe]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaycWkxZ0_2h"
      },
      "outputs": [],
      "source": [
        "pipeline_name = ['Decision_Tree', 'Naive_Bayes', 'Random_Forest', 'GBT_Classieifer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WZA9S5Z1Ckt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f123bd0-a8e9-40d5-846c-4f71652034ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Decision_Tree\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   90|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  425|\n",
            "+----+----------+-----+\n",
            "\n",
            "Decision_Tree\n",
            "accurary: 0.9023689877961235\n",
            "precision: 0.9023861171366594\n",
            "recall: 0.9476082004555809\n",
            "f1 Measure: 0.9013838761404175\n",
            "Processing Naive_Bayes\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|  140|\n",
            "|   0|       1.0|  136|\n",
            "|   0|       0.0|  742|\n",
            "|   1|       1.0|  375|\n",
            "+----+----------+-----+\n",
            "\n",
            "Naive_Bayes\n",
            "accurary: 0.8018664752333095\n",
            "precision: 0.8412698412698413\n",
            "recall: 0.8451025056947609\n",
            "f1 Measure: 0.8017054017715219\n",
            "Processing Random_Forest\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   78|\n",
            "|   0|       0.0|  846|\n",
            "|   1|       1.0|  437|\n",
            "|   0|       1.0|   32|\n",
            "+----+----------+-----+\n",
            "\n",
            "Random_Forest\n",
            "accurary: 0.9210337401292176\n",
            "precision: 0.9155844155844156\n",
            "recall: 0.9635535307517085\n",
            "f1 Measure: 0.9201958774939744\n",
            "Processing GBT_Classieifer\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   61|\n",
            "|   0|       1.0|   46|\n",
            "|   0|       0.0|  832|\n",
            "|   1|       1.0|  454|\n",
            "+----+----------+-----+\n",
            "\n",
            "GBT_Classieifer\n",
            "accurary: 0.9231873653984207\n",
            "precision: 0.9316909294512878\n",
            "recall: 0.9476082004555809\n",
            "f1 Measure: 0.9229450778381985\n"
          ]
        }
      ],
      "source": [
        "results = run_models_get_results(pipelines, pipeline_name, trainData, testData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-15NvygtmTE"
      },
      "source": [
        "Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHJCfxYYaITe"
      },
      "outputs": [],
      "source": [
        "#Models run with parameter tuning\n",
        "va = VectorAssembler(inputCols = input_cols, outputCol = 'features')\n",
        "\n",
        "clf = DecisionTreeClassifier(labelCol=\"spam\")\n",
        "\n",
        "nb = NaiveBayes(labelCol=\"spam\")\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"spam\")\n",
        "\n",
        "gbt = GBTClassifier(labelCol = 'spam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDynB7f3xWOv"
      },
      "outputs": [],
      "source": [
        "#Cost evaluator based on f1 score\n",
        "CV_eval = MulticlassClassificationEvaluator(labelCol='spam', predictionCol='prediction', metricName=\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sNPslH3xkA6"
      },
      "outputs": [],
      "source": [
        "#Building parameters to be tested\n",
        "dt_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "dt_grid = dt_grid.addGrid(clf.maxDepth,  [5, 8, 10, 15, 20, 30])\n",
        "dt_grid = dt_grid.addGrid(clf.minInstancesPerNode, [2,3,5,10])\n",
        "\n",
        "# Build the grid\n",
        "dt_grid = dt_grid.build()\n",
        "\n",
        "dt_cv = tune.CrossValidator(estimator=clf, estimatorParamMaps=dt_grid, evaluator=CV_eval, collectSubModels = True)\n",
        "\n",
        "nb_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "nb_grid = nb_grid.addGrid(nb.smoothing, [0.01, .2,.4,.5,.6,.8,1,1.2])\n",
        "\n",
        "# Build the grid\n",
        "nb_grid = nb_grid.build()\n",
        "\n",
        "nb_cv = tune.CrossValidator(estimator=nb, estimatorParamMaps=nb_grid, evaluator=CV_eval, collectSubModels = True)\n",
        "\n",
        "rf_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "rf_grid = rf_grid.addGrid(rf.numTrees, [10, 20, 30, 40, 50])\n",
        "rf_grid = rf_grid.addGrid(rf.maxDepth,  [10, 15, 20, 25, 30])\n",
        "\n",
        "# Build the grid\n",
        "rf_grid = rf_grid.build()\n",
        "\n",
        "rf_cv = tune.CrossValidator(estimator=rf, estimatorParamMaps=rf_grid, evaluator=CV_eval, collectSubModels = True)\n",
        "\n",
        "gbt_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "gbt_grid = gbt_grid.addGrid(gbt.minInfoGain, [.001, .005, .01, .05])\n",
        "gbt_grid = gbt_grid.addGrid(gbt.maxDepth,  [10, 20, 25, 30])\n",
        "\n",
        "# Build the grid\n",
        "gbt_grid = gbt_grid.build()\n",
        "\n",
        "gbt_cv = tune.CrossValidator(estimator=gbt, estimatorParamMaps=gbt_grid, evaluator=CV_eval, collectSubModels = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyVK2aOdMhvo",
        "outputId": "79c5fe00-f284-42f0-9a06-2325ebdf4523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Decision_Tree\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   61|\n",
            "|   0|       1.0|   48|\n",
            "|   0|       0.0|  830|\n",
            "|   1|       1.0|  454|\n",
            "+----+----------+-----+\n",
            "\n",
            "Decision_Tree\n",
            "accurary: 0.9217516152189519\n",
            "precision: 0.9315375982042648\n",
            "recall: 0.9453302961275627\n",
            "f1 Measure: 0.9215390178953249\n",
            "Processing Naive_Bayes\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|  144|\n",
            "|   0|       1.0|  132|\n",
            "|   0|       0.0|  746|\n",
            "|   1|       1.0|  371|\n",
            "+----+----------+-----+\n",
            "\n",
            "Naive_Bayes\n",
            "accurary: 0.8018664752333095\n",
            "precision: 0.8382022471910112\n",
            "recall: 0.8496583143507973\n",
            "f1 Measure: 0.8013710929840172\n",
            "Processing Random_Forest\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   37|\n",
            "|   0|       0.0|  852|\n",
            "|   1|       1.0|  478|\n",
            "|   0|       1.0|   26|\n",
            "+----+----------+-----+\n",
            "\n",
            "Random_Forest\n",
            "accurary: 0.9547738693467337\n",
            "precision: 0.9583802024746907\n",
            "recall: 0.9703872437357631\n",
            "f1 Measure: 0.9546705354072003\n",
            "Processing GBT_Classieifer\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   50|\n",
            "|   0|       1.0|   50|\n",
            "|   0|       0.0|  828|\n",
            "|   1|       1.0|  465|\n",
            "+----+----------+-----+\n",
            "\n",
            "GBT_Classieifer\n",
            "accurary: 0.9282124910265613\n",
            "precision: 0.9430523917995444\n",
            "recall: 0.9430523917995444\n",
            "f1 Measure: 0.9282124910265614\n"
          ]
        }
      ],
      "source": [
        "clf_pipe = Pipeline(stages=[va, dt_cv])\n",
        "\n",
        "nb_pipe = Pipeline(stages=[va, nb_cv])\n",
        "\n",
        "rf_pipe = Pipeline(stages=[va, rf_cv])\n",
        "\n",
        "gbt_pipe = Pipeline(stages=[va, gbt_cv])\n",
        "\n",
        "pipelines = [clf_pipe, nb_pipe, rf_pipe, gbt_pipe]\n",
        "\n",
        "pipeline_name = ['Decision_Tree', 'Naive_Bayes', 'Random_Forest', 'GBT_Classieifer']\n",
        "\n",
        "results = run_models_get_results(pipelines, pipeline_name, trainData, testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6-yZxqTu7gP",
        "outputId": "7382a4f8-cbc7-4d52-c682-b46ac79e94a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Tuned Max Depth: 10\n",
            "Decision Tree Tuned Min Instances Per Node: 3\n",
            "Naive Bayes Tuned Smoothing: 0.01\n",
            "Random Forest Tuned Max Depth: 20\n",
            "Random Forest Tuned Number Trees: 30\n",
            "GBT Tuned Max Depth: 10\n",
            "GBT Tuned Min Info Gain: 0.001\n"
          ]
        }
      ],
      "source": [
        "#Output of best features\n",
        "clf_pipe = Pipeline(stages=[va, dt_cv])\n",
        "\n",
        "nb_pipe = Pipeline(stages=[va, nb_cv])\n",
        "\n",
        "rf_pipe = Pipeline(stages=[va, rf_cv])\n",
        "\n",
        "gbt_pipe = Pipeline(stages=[va, gbt_cv])\n",
        "\n",
        "\n",
        "clf_fit = clf_pipe.fit(trainData)\n",
        "clf_prediction = clf_fit.transform(testData)\n",
        "\n",
        "clf_bestModel = clf_fit.stages[-1].bestModel\n",
        "clf_max_dep = clf_bestModel._java_obj.getMaxDepth()\n",
        "\n",
        "clf_bestModel = clf_fit.stages[-1].bestModel\n",
        "clf_min_int_node = clf_bestModel._java_obj.getMinInstancesPerNode()\n",
        "\n",
        "print(f'Decision Tree Tuned Max Depth: {clf_max_dep}')\n",
        "print(f'Decision Tree Tuned Min Instances Per Node: {clf_min_int_node}')\n",
        "\n",
        "nb_fit = nb_pipe.fit(trainData)\n",
        "nb_prediction = nb_fit.transform(testData)\n",
        "\n",
        "nb_bestModel = nb_fit.stages[-1].bestModel\n",
        "nb_smooth = nb_bestModel._java_obj.getSmoothing()\n",
        "\n",
        "print(f'Naive Bayes Tuned Smoothing: {nb_smooth}')\n",
        "\n",
        "rf_fit = rf_pipe.fit(trainData)\n",
        "rf_prediction = rf_fit.transform(testData)\n",
        "\n",
        "rf_bestModel = rf_fit.stages[-1].bestModel\n",
        "rf_max_dep = rf_bestModel._java_obj.getMaxDepth()\n",
        "\n",
        "rf_bestModel = rf_fit.stages[-1].bestModel\n",
        "rf_num_tree = rf_bestModel._java_obj.getNumTrees()\n",
        "\n",
        "print(f'Random Forest Tuned Max Depth: {rf_max_dep}')\n",
        "print(f'Random Forest Tuned Number Trees: {rf_num_tree}')\n",
        "\n",
        "gbt_fit = gbt_pipe.fit(trainData)\n",
        "gbt_prediction = gbt_fit.transform(testData)\n",
        "\n",
        "gbt_bestModel = gbt_fit.stages[-1].bestModel\n",
        "gbt_max_dep = gbt_bestModel._java_obj.getMaxDepth()\n",
        "\n",
        "gbt_bestModel = gbt_fit.stages[-1].bestModel\n",
        "gbt_min_in_gain = gbt_bestModel._java_obj.getMinInfoGain()\n",
        "\n",
        "print(f'GBT Tuned Max Depth: {gbt_max_dep}')\n",
        "print(f'GBT Tuned Min Info Gain: {gbt_min_in_gain}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcHt8gocnBrG"
      },
      "outputs": [],
      "source": [
        "#Cost eval seperate to be changed for next parameter tuning, in this case recall\n",
        "Cost_eval = MulticlassClassificationEvaluator(labelCol='spam', predictionCol='prediction', metricName=\"weightedRecall\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KAAlrMTnyQF"
      },
      "outputs": [],
      "source": [
        "dt_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "dt_grid = dt_grid.addGrid(clf.maxDepth,  [5, 8, 10, 15, 20, 30])\n",
        "dt_grid = dt_grid.addGrid(clf.minInstancesPerNode, [2,3,5,10])\n",
        "\n",
        "# Build the grid\n",
        "dt_grid = dt_grid.build()\n",
        "\n",
        "dt_cv = tune.CrossValidator(estimator=clf, estimatorParamMaps=dt_grid, evaluator=Cost_eval, collectSubModels = True)\n",
        "\n",
        "nb_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "nb_grid = nb_grid.addGrid(nb.smoothing, [.2,.4,.5,.6,.8,1])\n",
        "\n",
        "# Build the grid\n",
        "nb_grid = nb_grid.build()\n",
        "\n",
        "nb_cv = tune.CrossValidator(estimator=nb, estimatorParamMaps=nb_grid, evaluator=Cost_eval, collectSubModels = True)\n",
        "\n",
        "rf_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "rf_grid = rf_grid.addGrid(rf.numTrees, [10, 20, 30, 40, 50])\n",
        "rf_grid = rf_grid.addGrid(rf.maxDepth,  [10, 15, 20, 25, 30])\n",
        "\n",
        "# Build the grid\n",
        "rf_grid = rf_grid.build()\n",
        "\n",
        "rf_cv = tune.CrossValidator(estimator=rf, estimatorParamMaps=rf_grid, evaluator=Cost_eval, collectSubModels = True)\n",
        "\n",
        "gbt_grid = tune.ParamGridBuilder()\n",
        "\n",
        "# Add the hyperparameter\n",
        "gbt_grid = gbt_grid.addGrid(gbt.minInfoGain, [.001, .005, .01, .05])\n",
        "gbt_grid = gbt_grid.addGrid(gbt.maxDepth,  [10, 20, 25, 30])\n",
        "\n",
        "# Build the grid\n",
        "gbt_grid = gbt_grid.build()\n",
        "\n",
        "gbt_cv = tune.CrossValidator(estimator=gbt, estimatorParamMaps=gbt_grid, evaluator=Cost_eval, collectSubModels = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg5tV9lbuNTK",
        "outputId": "9607eadd-8c64-454d-c0cf-2ef4fdf3a056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Decision_Tree\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   61|\n",
            "|   0|       1.0|   48|\n",
            "|   0|       0.0|  830|\n",
            "|   1|       1.0|  454|\n",
            "+----+----------+-----+\n",
            "\n",
            "Decision_Tree\n",
            "accurary: 0.9217516152189519\n",
            "precision: 0.9315375982042648\n",
            "recall: 0.9453302961275627\n",
            "f1 Measure: 0.9215390178953249\n",
            "Processing Naive_Bayes\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|  145|\n",
            "|   0|       1.0|  132|\n",
            "|   0|       0.0|  746|\n",
            "|   1|       1.0|  370|\n",
            "+----+----------+-----+\n",
            "\n",
            "Naive_Bayes\n",
            "accurary: 0.801148600143575\n",
            "precision: 0.8372615039281706\n",
            "recall: 0.8496583143507973\n",
            "f1 Measure: 0.8006083298807796\n",
            "Processing Random_Forest\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   37|\n",
            "|   0|       0.0|  852|\n",
            "|   1|       1.0|  478|\n",
            "|   0|       1.0|   26|\n",
            "+----+----------+-----+\n",
            "\n",
            "Random_Forest\n",
            "accurary: 0.9547738693467337\n",
            "precision: 0.9583802024746907\n",
            "recall: 0.9703872437357631\n",
            "f1 Measure: 0.9546705354072003\n",
            "Processing GBT_Classieifer\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   50|\n",
            "|   0|       1.0|   50|\n",
            "|   0|       0.0|  828|\n",
            "|   1|       1.0|  465|\n",
            "+----+----------+-----+\n",
            "\n",
            "GBT_Classieifer\n",
            "accurary: 0.9282124910265613\n",
            "precision: 0.9430523917995444\n",
            "recall: 0.9430523917995444\n",
            "f1 Measure: 0.9282124910265614\n",
            "Processing Decision_Tree\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   61|\n",
            "|   0|       1.0|   48|\n",
            "|   0|       0.0|  830|\n",
            "|   1|       1.0|  454|\n",
            "+----+----------+-----+\n",
            "\n",
            "Decision_Tree\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 480\n",
            "False Negative Cost: 61\n",
            "Total Avg Cost: 0.38837042354630297\n",
            "Processing Naive_Bayes\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|  145|\n",
            "|   0|       1.0|  132|\n",
            "|   0|       0.0|  746|\n",
            "|   1|       1.0|  370|\n",
            "+----+----------+-----+\n",
            "\n",
            "Naive_Bayes\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 1320\n",
            "False Negative Cost: 145\n",
            "Total Avg Cost: 1.0516870064608759\n",
            "Processing Random_Forest\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   37|\n",
            "|   0|       0.0|  852|\n",
            "|   1|       1.0|  478|\n",
            "|   0|       1.0|   26|\n",
            "+----+----------+-----+\n",
            "\n",
            "Random_Forest\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 260\n",
            "False Negative Cost: 37\n",
            "Total Avg Cost: 0.2132089016511127\n",
            "Processing GBT_Classieifer\n",
            "Confusion Matrix\n",
            "+----+----------+-----+\n",
            "|spam|prediction|count|\n",
            "+----+----------+-----+\n",
            "|   1|       0.0|   50|\n",
            "|   0|       1.0|   50|\n",
            "|   0|       0.0|  828|\n",
            "|   1|       1.0|  465|\n",
            "+----+----------+-----+\n",
            "\n",
            "GBT_Classieifer\n",
            "True Positive Cost: 0\n",
            "True Negative Cost: 0\n",
            "False Positive Cost: 500\n",
            "False Negative Cost: 50\n",
            "Total Avg Cost: 0.3948312993539124\n"
          ]
        }
      ],
      "source": [
        "\n",
        "clf_pipe = Pipeline(stages=[va, dt_cv])\n",
        "\n",
        "nb_pipe = Pipeline(stages=[va, nb_cv])\n",
        "\n",
        "rf_pipe = Pipeline(stages=[va, rf_cv])\n",
        "\n",
        "gbt_pipe = Pipeline(stages=[va, gbt_cv])\n",
        "\n",
        "pipelines = [clf_pipe, nb_pipe, rf_pipe, gbt_pipe]\n",
        "\n",
        "pipeline_name = ['Decision_Tree', 'Naive_Bayes', 'Random_Forest', 'GBT_Classieifer']\n",
        "\n",
        "results = run_models_get_results(pipelines, pipeline_name, trainData, testData)\n",
        "\n",
        "results = run_models_get_results_get_cost(pipelines, pipeline_name, trainData, testData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vipe4Sw4uCzv",
        "outputId": "f9ec526c-ad45-42f7-d514-9dba0cc5cdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Tuned Max Depth: 10\n",
            "Decision Tree Tuned Min Instances Per Node: 3\n",
            "Naive Bayes Tuned Smoothing: 0.2\n",
            "Random Forest Tuned Max Depth: 20\n",
            "Random Forest Tuned Number Trees: 30\n",
            "GBT Tuned Max Depth: 10\n",
            "GBT Tuned Min Info Gain: 0.001\n"
          ]
        }
      ],
      "source": [
        "clf_pipe = Pipeline(stages=[va, dt_cv])\n",
        "\n",
        "nb_pipe = Pipeline(stages=[va, nb_cv])\n",
        "\n",
        "rf_pipe = Pipeline(stages=[va, rf_cv])\n",
        "\n",
        "gbt_pipe = Pipeline(stages=[va, gbt_cv])\n",
        "\n",
        "\n",
        "clf_fit = clf_pipe.fit(trainData)\n",
        "clf_prediction = clf_fit.transform(testData)\n",
        "\n",
        "clf_bestModel = clf_fit.stages[-1].bestModel\n",
        "clf_max_dep = clf_bestModel._java_obj.getMaxDepth()\n",
        "\n",
        "clf_bestModel = clf_fit.stages[-1].bestModel\n",
        "clf_min_int_node = clf_bestModel._java_obj.getMinInstancesPerNode()\n",
        "\n",
        "print(f'Decision Tree Tuned Max Depth: {clf_max_dep}')\n",
        "print(f'Decision Tree Tuned Min Instances Per Node: {clf_min_int_node}')\n",
        "\n",
        "nb_fit = nb_pipe.fit(trainData)\n",
        "nb_prediction = nb_fit.transform(testData)\n",
        "\n",
        "nb_bestModel = nb_fit.stages[-1].bestModel\n",
        "nb_smooth = nb_bestModel._java_obj.getSmoothing()\n",
        "\n",
        "print(f'Naive Bayes Tuned Smoothing: {nb_smooth}')\n",
        "\n",
        "rf_fit = rf_pipe.fit(trainData)\n",
        "rf_prediction = rf_fit.transform(testData)\n",
        "\n",
        "rf_bestModel = rf_fit.stages[-1].bestModel\n",
        "rf_max_dep = rf_bestModel._java_obj.getMaxDepth()\n",
        "\n",
        "rf_bestModel = rf_fit.stages[-1].bestModel\n",
        "rf_num_tree = rf_bestModel._java_obj.getNumTrees()\n",
        "\n",
        "print(f'Random Forest Tuned Max Depth: {rf_max_dep}')\n",
        "print(f'Random Forest Tuned Number Trees: {rf_num_tree}')\n",
        "\n",
        "gbt_fit = gbt_pipe.fit(trainData)\n",
        "gbt_prediction = gbt_fit.transform(testData)\n",
        "\n",
        "gbt_bestModel = gbt_fit.stages[-1].bestModel\n",
        "gbt_max_dep = gbt_bestModel._java_obj.getMaxDepth()\n",
        "\n",
        "gbt_bestModel = gbt_fit.stages[-1].bestModel\n",
        "gbt_min_in_gain = gbt_bestModel._java_obj.getMinInfoGain()\n",
        "\n",
        "print(f'GBT Tuned Max Depth: {gbt_max_dep}')\n",
        "print(f'GBT Tuned Min Info Gain: {gbt_min_in_gain}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}